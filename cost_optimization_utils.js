// cost_optimization_utils.js
// ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

/**
 * Rate Limiter - API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ
 * Notion API: ì´ˆë‹¹ 3íšŒ ì œí•œ
 * OpenAI API: í† í° ê¸°ë°˜ ìš”ê¸ˆì œì— ë”°ë¼ ë‹¤ë¦„
 */
export class RateLimiter {
	constructor(maxRequestsPerSecond = 3) {
		this.maxRequests = maxRequestsPerSecond;
		this.requests = [];
	}

	async waitIfNeeded() {
		const now = Date.now();
		// 1ì´ˆ ì´ìƒ ì§€ë‚œ ìš”ì²­ ì œê±°
		this.requests = this.requests.filter((time) => now - time < 1000);

		// ì´ˆë‹¹ ì œí•œì— ë„ë‹¬í–ˆìœ¼ë©´ ëŒ€ê¸°
		if (this.requests.length >= this.maxRequests) {
			const oldestRequest = Math.min(...this.requests);
			const waitTime = 1000 - (now - oldestRequest) + 10; // 10ms ì—¬ìœ 
			if (waitTime > 0) {
				await new Promise((resolve) => setTimeout(resolve, waitTime));
			}
		}

		this.requests.push(Date.now());
	}

	reset() {
		this.requests = [];
	}
}

/**
 * ì¬ì‹œë„ ë¡œì§ - Exponential Backoff
 */
export async function retryWithBackoff(
	fn,
	maxRetries = 3,
	baseDelay = 1000,
	onRetry = null
) {
	let lastError;

	for (let attempt = 0; attempt < maxRetries; attempt++) {
		try {
			return await fn();
		} catch (error) {
			lastError = error;

			// ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
			if (attempt < maxRetries - 1) {
				const delay = baseDelay * Math.pow(2, attempt); // Exponential backoff
				if (onRetry) {
					onRetry(attempt + 1, maxRetries, delay, error);
				}
				await new Promise((resolve) => setTimeout(resolve, delay));
			}
		}
	}

	throw lastError;
}

/**
 * ë°°ì¹˜ ì²˜ë¦¬ - ë°°ì—´ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
 * OpenAI API í˜¸ì¶œ ìµœì†Œí™”: ì—¬ëŸ¬ í•­ëª©ì„ í•œ ë²ˆì— ì²˜ë¦¬
 */
export function chunkArray(array, chunkSize) {
	const chunks = [];
	for (let i = 0; i < array.length; i += chunkSize) {
		chunks.push(array.slice(i, i + chunkSize));
	}
	return chunks;
}

/**
 * ì§„í–‰ ìƒí™© ì¶”ì  ë° ì¬ê°œ(Resume) ê¸°ëŠ¥
 */
export class ProgressTracker {
	constructor(storageKey = 'progress') {
		this.storageKey = storageKey;
		this.progress = {
			processed: 0,
			total: 0,
			lastProcessedId: null,
			timestamp: Date.now(),
			errors: [],
		};
	}

	load() {
		try {
			const stored = localStorage.getItem(this.storageKey);
			if (stored) {
				this.progress = JSON.parse(stored);
				return true;
			}
		} catch (err) {
			console.warn('ì§„í–‰ ìƒí™© ë¡œë“œ ì‹¤íŒ¨:', err);
		}
		return false;
	}

	save() {
		try {
			this.progress.timestamp = Date.now();
			localStorage.setItem(this.storageKey, JSON.stringify(this.progress));
			return true;
		} catch (err) {
			console.warn('ì§„í–‰ ìƒí™© ì €ì¥ ì‹¤íŒ¨:', err);
			return false;
		}
	}

	update(processed, lastProcessedId = null) {
		this.progress.processed = processed;
		if (lastProcessedId) {
			this.progress.lastProcessedId = lastProcessedId;
		}
		this.save();
	}

	addError(error, itemId = null) {
		this.progress.errors.push({
			timestamp: Date.now(),
			error: error.message || String(error),
			itemId,
		});
		this.save();
	}

	reset() {
		this.progress = {
			processed: 0,
			total: 0,
			lastProcessedId: null,
			timestamp: Date.now(),
			errors: [],
		};
		this.save();
	}

	getStatus() {
		const percentage =
			this.progress.total > 0
				? ((this.progress.processed / this.progress.total) * 100).toFixed(2)
				: 0;
		return {
			...this.progress,
			percentage,
			remaining: this.progress.total - this.progress.processed,
		};
	}
}

/**
 * ìºì‹± ì‹œìŠ¤í…œ - ì¤‘ë³µ API í˜¸ì¶œ ë°©ì§€
 * OpenAI API í˜¸ì¶œ ìµœì†Œí™”: ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ì€ ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
 */
export class SimpleCache {
	constructor(ttl = 24 * 60 * 60 * 1000) {
		// ê¸°ë³¸ TTL: 24ì‹œê°„
		this.cache = new Map();
		this.ttl = ttl;
	}

	get(key) {
		const item = this.cache.get(key);
		if (!item) return null;

		// TTL ì²´í¬
		if (Date.now() - item.timestamp > this.ttl) {
			this.cache.delete(key);
			return null;
		}

		return item.value;
	}

	set(key, value) {
		this.cache.set(key, {
			value,
			timestamp: Date.now(),
		});
	}

	has(key) {
		const item = this.cache.get(key);
		if (!item) return false;

		// TTL ì²´í¬
		if (Date.now() - item.timestamp > this.ttl) {
			this.cache.delete(key);
			return false;
		}

		return true;
	}

	clear() {
		this.cache.clear();
	}

	size() {
		return this.cache.size;
	}
}

/**
 * OpenAI API í˜¸ì¶œ ìµœì†Œí™” ì „ëµ
 * 
 * 1. ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ í•­ëª©ì„ í•œ ë²ˆì— ì²˜ë¦¬
 * 2. ìºì‹±: ë™ì¼í•œ ì…ë ¥ì€ ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
 * 3. ìŠ¤ë§ˆíŠ¸ í•„í„°ë§: ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ëŠ” í•­ëª© ì œì™¸
 * 4. ì§„í–‰ ìƒí™© ì €ì¥: ì¤‘ë‹¨ í›„ ì¬ê°œ ê°€ëŠ¥
 */
export class OpenAIOptimizer {
	constructor(options = {}) {
		this.cache = options.cache || new SimpleCache();
		this.batchSize = options.batchSize || 10; // í•œ ë²ˆì— ì²˜ë¦¬í•  í•­ëª© ìˆ˜
		this.enableCache = options.enableCache !== false;
		this.progressTracker = options.progressTracker || null;
	}

	/**
	 * í•­ëª©ì˜ ê³ ìœ  í‚¤ ìƒì„± (ìºì‹±ìš©)
	 */
	getItemKey(item) {
		// í•­ëª©ì˜ ê³ ìœ  IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‚¤ ìƒì„±
		return item.id || JSON.stringify(item);
	}

	/**
	 * ì²˜ë¦¬í•  í•­ëª© í•„í„°ë§ (ìºì‹œì— ìˆëŠ” í•­ëª© ì œì™¸)
	 */
	filterUnprocessedItems(items) {
		if (!this.enableCache) {
			return items;
		}

		return items.filter((item) => {
			const key = this.getItemKey(item);
			return !this.cache.has(key);
		});
	}

	/**
	 * í•­ëª©ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
	 */
	async processBatch(items, processFn, options = {}) {
		const { onProgress = null, onError = null } = options;

		// ìºì‹œì—ì„œ ì œì™¸ëœ í•­ëª©ë§Œ í•„í„°ë§
		const unprocessedItems = this.filterUnprocessedItems(items);
		const batches = chunkArray(unprocessedItems, this.batchSize);

		console.log(
			`ğŸ“Š ì²˜ë¦¬ ê³„íš: ì´ ${items.length}ê°œ í•­ëª© ì¤‘ ${unprocessedItems.length}ê°œ ë¯¸ì²˜ë¦¬, ${batches.length}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬`
		);

		let processedCount = 0;
		const results = [];

		for (let i = 0; i < batches.length; i++) {
			const batch = batches[i];
			try {
				// ë°°ì¹˜ ì²˜ë¦¬ (OpenAI API í˜¸ì¶œ ìµœì†Œí™”)
				const batchResults = await processFn(batch);

				// ê²°ê³¼ ìºì‹±
				batch.forEach((item, index) => {
					const key = this.getItemKey(item);
					const result = batchResults[index];
					this.cache.set(key, result);
				});

				results.push(...batchResults);
				processedCount += batch.length;

				// ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
				if (this.progressTracker) {
					this.progressTracker.update(processedCount);
				}

				if (onProgress) {
					onProgress({
						processed: processedCount,
						total: items.length,
						currentBatch: i + 1,
						totalBatches: batches.length,
					});
				}
			} catch (error) {
				if (onError) {
					onError(error, batch, i);
				} else {
					console.error(`ë°°ì¹˜ ${i + 1} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
				}
				throw error;
			}
		}

		return results;
	}
}
